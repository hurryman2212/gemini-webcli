#!/usr/bin/env python3

import argparse, asyncio, inquirer, json, os, pyperclip, re, sys

import tkinter as tk

from gemini_webapi import GeminiClient, set_log_level
from loguru import logger

from tkinter import Label
from PIL import Image, ImageTk
from prompt_toolkit import PromptSession, prompt
from prompt_toolkit.formatted_text import HTML
from prompt_toolkit.key_binding import KeyBindings
from prompt_toolkit.styles import Style
from rich.console import Console
from rich.markdown import Markdown
from typing import Union, Any

session = PromptSession()

bindings = KeyBindings()


@bindings.add("c-d")
def _(event):
    event.current_buffer.validate_and_handle()


async def prompt_with_editing(prefix: str = "") -> str:
    def continuation(width, line_number, is_soft_wrap):
        return ""

    return await session.prompt_async(
        prefix,
        placeholder=HTML("<u><ansigreen>Enter Ctrl+C to quit.</ansigreen></u>"),
        multiline=True,
        key_bindings=bindings,
        prompt_continuation=continuation,
        style=Style.from_dict({"prompt": "ansigreen"}),
    )


async def loading_animation():
    frames = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]
    idx = 0
    try:
        while True:
            print(f"\r\033[96m{frames[idx]} Processing...\033[0m", end="", flush=True)
            idx = (idx + 1) % len(frames)
            await asyncio.sleep(0.1)
    except asyncio.CancelledError:
        print("\r\033[K", end="", flush=True)


def _encode_metadata_list(items: list[str]) -> bytes:
    payload = bytearray(b"gemini-webcli-metadata-v1")
    payload.append(len(items))
    for item in items:
        encoded = item.encode("utf-8")
        payload.extend(len(encoded).to_bytes(2, "big"))
        payload.extend(encoded)
    return bytes(payload)


def _decode_metadata_list(raw: bytes) -> list[str] | None:
    if not raw or not raw.startswith(b"gemini-webcli-metadata-v1"):
        return None

    try:
        count = raw[4]
        pos = 5
        items: list[str] = []
        for _ in range(count):
            if pos + 2 > len(raw):
                return None
            length = int.from_bytes(raw[pos : pos + 2], "big")
            pos += 2
            if pos + length > len(raw):
                return None
            items.append(raw[pos : pos + length].decode("utf-8"))
            pos += length
        return items
    except Exception:
        return None


def show_image(image_path: str) -> None:
    window = tk.Tk()
    window.title("Image")
    img = Image.open(image_path)
    photo = ImageTk.PhotoImage(img)
    label = Label(window, image=photo)
    label.image = photo
    label.pack()
    window.mainloop()


# Add prefix of the directory path of `gemini-webcli`
COOKIE_FILEPATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), "cookie.bin")


def save_metadata(metadata: Union[bytes, list[Any]]) -> None:
    if isinstance(metadata, list) and all(item is None for item in metadata):
        return

    if isinstance(metadata, bytes):
        to_write = metadata
    elif isinstance(metadata, list):
        to_write = _encode_metadata_list([str(item) for item in metadata])
    else:
        raise TypeError("metadata must be bytes or list")

    with open(COOKIE_FILEPATH, "wb") as f:
        f.write(to_write)


def load_metadata() -> Union[bytes, list[Any]] | None:
    try:
        with open(COOKIE_FILEPATH, "rb") as f:
            raw = f.read()

        decoded = _decode_metadata_list(raw)
        if decoded is not None:
            return decoded

        try:
            data = json.loads(raw.decode())
            if isinstance(data, dict) and data.get("type") == "bytes":
                return bytes.fromhex(data["data"])
            if isinstance(data, dict) and data.get("type") == "list":
                return data.get("data")
        except Exception:
            return None
    except FileNotFoundError:
        return None


console = Console()


async def main():
    parser = argparse.ArgumentParser(description="Gemini Web CLI")
    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        "-n",
        "--nyarchassistant",
        nargs=2,
        metavar=("PROMPT", "SYSTEM_PROMPT"),
        type=str,
        help="Prompt and system prompt in nyarchassistant JSON format (file upload is supported)",
    )
    group.add_argument(
        "-e",
        "--explain",
        metavar="COMMAND",
        type=str,
        help="Explain command noninteractively (and copy result to clipboard)",
    )
    group.add_argument(
        "-s",
        "--suggest",
        metavar="DESCRIPTION",
        type=str,
        help="Suggest command noninteractively (and copy result to clipboard)",
    )
    args = parser.parse_args()

    prompt, system_prompt = (
        args.nyarchassistant if args.nyarchassistant else (None, None)
    )
    command = args.explain if args.explain else None
    description = args.suggest if args.suggest else None

    if prompt:
        LOG_LEVEL = "TRACE"
    else:
        LOG_LEVEL = "CRITICAL"
    set_log_level(LOG_LEVEL)
    logger.add(
        sys.stderr,
        level=LOG_LEVEL,
        filter=lambda record: record["name"] == "__main__",
    )

    logger.info("Starting gemini-webcli...")
    client = GeminiClient()
    await client.init(timeout=180, auto_close=True, close_delay=300, auto_refresh=True)

    if prompt or command or description:
        if prompt:
            logger.info("Processing JSON prompts...")
            # Remove `'` at the beginning and the end from `prompt`
            prompt = prompt.strip(" '")
            logger.debug(f"prompt: {str(prompt)}")
            # `prompt` is now starting with '[' and ending with ']' - Convert it to array of dictionaries
            prompt = prompt.replace("'\\''", "'").replace("}{", "},{")
            try:
                orig_prompt_jsons = json.loads(prompt)
            except json.JSONDecodeError as e:
                logger.critical(f"Failed to decode JSON: {e}")
                exit(1)
            logger.debug(f"orig_prompt_jsons: {str(orig_prompt_jsons)}")
            logger.debug(f"system_prompt: {system_prompt}")

            list_to_send = []
            path_list = []
            uuid_to_search = None
            uuid_to_update = None
            for idx, each_json in enumerate(orig_prompt_jsons):
                if idx % 2 == 0:
                    if len(orig_prompt_jsons) <= 3:
                        list_to_send.append(each_json)
                        pattern = (
                            r"```(?:image|file)(?:\\n|\s)+([\s\S]*?)(?:\\n|\s)+```"
                        )
                        extracted_paths = re.findall(pattern, each_json["Message"])
                        path_list += [path.strip() for path in extracted_paths]
                    else:
                        if idx == len(orig_prompt_jsons) - 1:
                            prompt_to_send = each_json["Message"]
                            pattern = (
                                r"```(?:image|file)(?:\\n|\s)+([\s\S]*?)(?:\\n|\s)+```"
                            )
                            extracted_paths = re.findall(pattern, each_json["Message"])
                            path_list += [path.strip() for path in extracted_paths]
                else:
                    if len(orig_prompt_jsons) <= 3:
                        tmp_dict = {
                            "User": each_json["User"],
                            "Message": each_json["Message"],
                        }
                        list_to_send.append(tmp_dict)
                    uuid_to_search = str(uuid_to_update) if uuid_to_update else None
                    uuid_to_update = str(each_json["UUID"])

            GEM_NAME = "gemini-webcli"

            logger.info(f"Fetching old {GEM_NAME} gem...")
            await client.fetch_gems()
            old_gem = client.gems.get(name=GEM_NAME)
            if old_gem is None:
                logger.info(f"No existing gem found: Creating {GEM_NAME} gem...")
                updated_gem = await client.create_gem(
                    name=GEM_NAME,
                    prompt=system_prompt,
                )
            if old_gem is not None:
                logger.warning(f"Updating old {GEM_NAME} gem...")
                updated_gem = await client.update_gem(
                    gem=old_gem,
                    name=GEM_NAME,
                    prompt=system_prompt,
                )

            if len(path_list) == 0:
                logger.debug("No files to send: Sending only prompt message...")
                path_list = None
            else:
                logger.debug(f"path_list: {str(path_list)}")
            if len(orig_prompt_jsons) <= 3:
                prompt_to_send = str(list_to_send)
            logger.debug(f"prompt_to_send: {prompt_to_send}")

            # Add prefix of the directory path of `gemini-webcli`
            CACHE_FILEPATH = os.path.join(
                os.path.dirname(os.path.abspath(__file__)), "cache.json"
            )

            previous_session = None
            logger.debug(f"uuid_to_search: {uuid_to_search}")
            # if cache file does not exist, create an empty one
            if not os.path.exists(CACHE_FILEPATH):
                with open(CACHE_FILEPATH, "w+") as cache_file:
                    json.dump({}, cache_file)
            # Load cache JSON file and search for the metadata binary with `uuid_to_search` as key
            with open(CACHE_FILEPATH, "r") as cache_file:
                try:
                    cache_data = json.load(cache_file)
                except:
                    cache_data = {}
            logger.debug(f"cache_data: {cache_data}")
            if uuid_to_search:
                previous_session = cache_data[uuid_to_search]
            logger.debug(f"previous_session: {str(previous_session)}")
            chat = client.start_chat(
                model="gemini-3.0-pro",
                gem=updated_gem,
                metadata=previous_session,
            )

            logger.info(f"Sending request with {GEM_NAME} gem...")
            resp = await chat.send_message(prompt_to_send, files=path_list)

            logger.info("Response received: " + str(resp))
            print(resp.text)

            # Save the metadata binary to cache JSON file with `uuid_to_update` as key
            # (if cache file does not exist, create an empty one)
            logger.debug(f"uuid_to_update: {uuid_to_update}")
            if uuid_to_update:
                with open(CACHE_FILEPATH, "w+") as cache_file:
                    cache_data[uuid_to_update] = chat.metadata
                    # Delete previous file content before writing
                    cache_file.truncate(0)
                    json.dump(cache_data, cache_file)
        elif command:
            resp = await client.generate_content(
                f'Explain the following command with short single line summary (skip the sentence structure; if you cannot be sure, reply "N/A"): {command}',
                model="gemini-3.0-pro",
            )
            if resp.text.upper() == "N/A":
                print("\033[91mN/A\033[0m")
            else:
                console.print(Markdown(resp.text))
        else:
            resp = await client.generate_content(
                f'Reply with only the command for the following description, without quotation marks (if you cannot be sure, reply "N/A"): {description}',
                model="gemini-3.0-pro",
            )
            if resp.text.upper() == "N/A":
                print("\033[91mN/A\033[0m")
            else:
                print(resp.text)
            pyperclip.copy(resp.text)
        return

    previous_session = load_metadata()

    questions = [
        inquirer.List(
            "method",
            message="Choose method:",
            choices=["send_message()", "generate_content()"],
            carousel=True,
        ),
    ]
    answers = inquirer.prompt(questions)
    if answers is None:
        return
    method = answers["method"]

    print("\033[96mUse Ctrl+D (EOF) key to send.\n\033[0m")

    PROMPT_PREFIX = "[User]\n"
    if method != "send_message()":
        while True:
            try:
                query = await prompt_with_editing(PROMPT_PREFIX)
            except KeyboardInterrupt:
                return

            if not query.strip():
                continue

            animation_task = asyncio.create_task(loading_animation())
            try:
                resp = await client.generate_content(f"{query}")
            finally:
                animation_task.cancel()
                try:
                    await animation_task
                except asyncio.CancelledError:
                    pass

            print("")

            for _, image in enumerate(resp.images):
                await image.save(path="./", filename=f"temp.png", verbose=True)
                show_image("temp.png")

            os.remove("temp.png")
    else:
        chat = client.start_chat(model="gemini-3.0-pro", metadata=previous_session)

        while True:
            try:
                query = await prompt_with_editing(PROMPT_PREFIX)
            except KeyboardInterrupt:
                break

            if not query.strip():
                continue

            animation_task = asyncio.create_task(loading_animation())
            try:
                resp = await chat.send_message(f"{query}")
            finally:
                animation_task.cancel()
                try:
                    await animation_task
                except asyncio.CancelledError:
                    pass

            print("\n\033[94m[Gemini]\033[0m")
            console.print(Markdown(f"{resp.text}"))
            print("")

            if resp.images:
                for _, image in enumerate(resp.images):
                    await image.save(path="./", filename=f"temp.png", verbose=True)
                    show_image("temp.png")

                os.remove("temp.png")

            save_metadata(chat.metadata)


asyncio.run(main())
